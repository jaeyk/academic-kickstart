install.packages("blogdown")
blogdown::install_hugo(version = "0.73.0", force = TRUE)
devtools::install_github("rstudio/addinexamples", type = "source")
blogdown:::serve_site()
I am a proud recipient of the Outstanding Graduate Student Instructor Award. I teach computational social science at both the graduate and undergraduate levels, including semester-long courses and short workshops. I also served as a [Data Science Education Program Fellow](https://ocean.sagepub.com/blog/skills/5-principles-to-get-undergraduates-involved-in-real-world-data-science-projects) for the Discovery Program at UC Berkeley.
blogdown:::serve_site()
blogdown:::serve_site()
blogdown:::serve_site()
blogdown:::serve_site()
blogdown::stop_server()
blogdown:::serve_site()
blogdown:::serve_site()
blogdown:::serve_site()
blogdown:::serve_site()
blogdown:::serve_site()
blogdown:::serve_site()
blogdown::update_hugo()
blogdown:::new_post_addin()
blogdown:::new_post_addin()
blogdown:::serve_site()
---
title: "Twitter Analysis"
date: 2020-07-20T01:16:29-07:00
draft: true
---
blogdown:::serve_site()
blogdown:::serve_site()
blogdown:::serve_site()
blogdown:::serve_site()
blogdown:::serve_site()
blogdown:::serve_site()
blogdown:::serve_site()
blogdown:::serve_site()
blogdown:::serve_site()
servr::daemon_stop(1)
blogdown:::serve_site()
blogdown:::serve_site()
stop_server()
blogdown:::serve_site()
blogdown:::serve_site()
blogdown:::new_post_addin()
blogdown:::serve_site()
blogdown:::serve_site()
blogdown:::serve_site()
blogdown:::serve_site()
blogdown:::serve_site()
blogdown:::serve_site()
blogdown:::serve_site()
blogdown:::serve_site()
blogdown:::serve_site()
blogdown:::serve_site()
blogdown:::serve_site()
blogdown:::serve_site()
blogdown:::serve_site()
servr::stop_server
servr::daemon_stop(1)
blogdown:::serve_site()
blogdown:::serve_site()
blogdown:::serve_site()
ls
blogdown:::serve_site()
blogdown:::serve_site()
blogdown:::serve_site()
blogdown:::serve_site()
blogdown:::serve_site()
blogdown:::serve_site()
blogdown:::serve_site()
blogdown:::serve_site()
blogdown:::serve_site()
blogdown:::serve_site()
blogdown:::serve_site()
blogdown:::serve_site()
blogdown:::serve_site()
blogdown:::serve_site()
blogdown:::serve_site()
blogdown:::serve_site()
blogdown:::serve_site()
blogdown:::serve_site()
blogdown:::serve_site()
blogdown:::serve_site()
install.packages(c("chron", "dplyr", "StanHeaders"))
blogdown:::serve_site()
blogdown:::serve_site()
blogdown:::serve_site()
blogdown:::serve_site()
blogdown:::serve_site()
blogdown:::serve_site()
blogdown:::serve_site()
blogdown:::serve_site()
blogdown:::serve_site()
blogdown:::serve_site()
blogdown:::serve_site()
install.packages(c("bit64", "mnormt", "plm", "spatialwidget", "TTR", "xmlparsedata"))
blogdown:::serve_site()
knitr::opts_chunk$set(fig.width = 12, fig.height = 8,
echo = FALSE, warning = FALSE, message = FALSE) # global setting for enlarging image size
# Clean up the environment
# rm(list = ls())
# Import libraries (adapted from this link: https://stackoverflow.com/questions/4090169/elegant-way-to-check-for-missing-packages-and-install-them)
if (!require("pacman")) install.packages("pacman")
pacman::p_load(
tidyverse, # for the tidyverse framework
ggthemes, # for fancy ggplot themes
psych, # for psychological tools
factoextra, # for extracting and visualizing the results of multivariate data analyses
FactoMineR, # for multivariate exploratory data analysis and data mining
conflicted, # for resolving conflicting functions
ggthemes, # for fancy ggplot themes
here, # for self-contained projects
ggpubr # for pub-ready themes
)
devtools::install_github("jaeyk/makereproducible",
dependencies = TRUE)
library(makereproducible)
# for publication-friendly theme
theme_set(theme_pubr())
# Prefer select from dplyr
conflict_prefer("select", "dplyr")
conflict_prefer("filter", "dplyr")
# Import
imputed <- read.csv("/home/jae/analyzing-racial-lived-experience/processed_data/imputed.csv")[,-1] %>% # Ignore the first column
filter(race == "AAPI")
# Selecting variables
vars <- imputed %>%
select(q5_1_b, q5_1_c, q5_1_d, q5_1_e, q5_1_g, q5_1_h, q5_1_i, # micro-aggression
q5_2_a, q5_2_b, q5_2_c, q5_2_d, q5_2_e, q5_2_f, # discrimination
q5_7_a, q5_7_b, q5_7_c, q5_7_d, q5_7_e, q5_7_f, q5_7_g, q5_7_h, q5_7_i, q5_7_j, q5_7_k, q5_7_l) # everyday challenge
# Renaming these variables
vars <- vars %>%
rename(# micro-agression
service_unfriendly = q5_1_b,
english_proficiency = q5_1_c,
afraid_of_you = q5_1_d,
thought_dishonest = q5_1_e,
insulted = q5_1_g,
threatened = q5_1_h,
name_mispronounced = q5_1_i,
# discrimination
promotion_denied = q5_2_a,
unfairly_fired = q5_2_b,
job_rejected = q5_2_c,
policy_brutality = q5_2_d,
housing_discrimination = q5_2_e,
neighbor_hostility = q5_2_f,
# everyday challenge
visa_delay = q5_7_a,
school_quality = q5_7_b,
school_bullied = q5_7_c,
college_affordability = q5_7_d,
elderly_care = q5_7_e,
medical_care = q5_7_f,
rent_affordability = q5_7_g,
college_debt = q5_7_h,
medical_debt = q5_7_i,
card_debt = q5_7_j,
child_care = q5_7_k,
little_saving = q5_7_l)
set.seed(1234)
fa.parallel(vars,
fm = 'ml', # eigenvalues using maxium likelihood (common factor model)
fa = 'fa', # principal axis factor analysis
n.iter = 50, # number of iterations
SMC = TRUE)
# Factor analysis
factor_analysis <- fa(vars,
nfactors = 3, # three factors
rotate = 'oblimin',
fm = 'ml') # ML estimation
# Summary
summary(factor_analysis)
# Extract factor loadings
factor_frame <- factor_analysis$loadings %>%
unclass() %>%
as.data.frame()
# Putting them into a data frame
factor_df <- data.frame(Measures = rownames(factor_frame),
everyday_challenge = factor_frame$ML1,
micro_aggression = factor_frame$ML2,
discrimination = factor_frame$ML3)
factor_df %>%
gather(key = "Factor", value = "Loading",
everyday_challenge:discrimination) %>%
ggplot(aes(x = factor(Measures, levels = factor_df$Measures), y = Loading, fill = Loading)) +
geom_bar(stat = "identity") +
coord_flip() +
facet_wrap(~Factor, nrow = 1) +
scale_fill_gradient2(name = "Loading",
high = "blue", mid = "white", low = "red", midpoint = 0, guide = F) +
labs(y= "Loading Strength", x = "Measures",
title = "Factor Analysis Results",
subtitle = "Only included Asian Americans",
caption = "Source: National Asian American Survey (2016)")
ggsave(make_here("/home/jae/analyzing-racial-lived-experience/outputs/factor_analysis.png"), height = 6, width = 8)
# Micro-aggression
micro_aggression <- vars %>%
select(service_unfriendly,
english_proficiency,
afraid_of_you,
thought_dishonest,
insulted,
threatened,
name_mispronounced) %>%
summarise_all(funs(mean)) %>%
gather(Measurees, micro_aggression_avg, c(1:7))
# Discrimination
discrimination <- vars %>%
select(promotion_denied,
unfairly_fired,
job_rejected,
policy_brutality,
housing_discrimination,
neighbor_hostility) %>%
summarise_all(funs(mean)) %>%
gather(Measurees, discrimination_avg, c(1:6))
# Everyday challenge
everyday_challenge <- vars %>%
select(visa_delay,
school_quality,
school_bullied,
college_affordability,
elderly_care,
medical_care,
rent_affordability,
college_debt,
medical_debt,
card_debt,
child_care,
little_saving) %>%
summarise_all(funs(mean)) %>%
gather(Measurees, micro_aggression_avg, c(1:12))
# Replace old questions
factored <- rbind(data.frame("Weighted" =
factor_df$micro_aggression[1:7] * micro_aggression[,2]),
data.frame("Weighted" = factor_df$discrimination[8:(8+5)] * discrimination[,2]),
data.frame("Weighted" = factor_df$everyday_challenge[(8+6):(8+6+11)] * everyday_challenge[,2]))
factored$factor <- c(rep("micro_aggression", 7), rep("discrimination", 6), rep("everyday_challenge", 12))
# Non-weighted average responses
non_factored <- data.frame("Non_weighted" = vars %>%
summarise_all(funs(mean)) %>% as.numeric(),
"factor" = c(rep("micro_aggression", 7), rep("discrimination", 6), rep("everyday_challenge", 12)))
# Merge them
weighted_comparison <- merge(factored, non_factored) %>%
gather(weighted, value, Weighted:Non_weighted)
weighted_comparison %>%
group_by(factor, weighted) %>% # group to summarize
summarise(mean = mean(value), # summarize mean, standard deviation, and n
sd = sd(value),
n = n()) %>%
mutate(se = sd / sqrt(n), # calculate standard errors and confidence intervals
lower.ci = mean - qt(1 - (0.05 / 2), n - 1) * se,
upper.ci = mean + qt(1 - (0.05 / 2), n - 1) * se) %>%
ggplot(aes(x = reorder(factor, mean), y = mean, ymax = upper.ci, ymin = lower.ci, color = weighted)) +
geom_pointrange(size = 0.7) + # point estimates plus confidence intervals
theme_base() +
coord_flip() +
labs(title = "Three Dimensions of Lived Racial Experience",
subtitle = "Only included Asian Americans",
y= "Average score of survey responses", x = "Factor",
caption = "Source: National Asian American Survey (2016)",
col = "Weighted")
ggsave(make_here("/home/jae/analyzing-racial-lived-experience/outputs/weighted_responses.png"), width = 10)
blogdown:::serve_site()
